<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>跳跃表</title>
    <url>/2020/02/20/skiplist/</url>
    <content><![CDATA[<h1 id="跳跃表"><a href="#跳跃表" class="headerlink" title="跳跃表"></a>跳跃表</h1><blockquote>
<p>跳跃表（skiplist）作为一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到快速访问节点的目的。<strong>跳跃表以有序的方式在层次化的链表中保存元素， 效率和平衡树媲美</strong> </p>
</blockquote>
<p>本文接下来将从三部分来分析skiplist，即为什么会有跳跃表、怎么理解跳跃表和跳跃表的优缺点！</p>
<a id="more"></a>

<h2 id="Why-is-skiplist"><a href="#Why-is-skiplist" class="headerlink" title="Why is skiplist?"></a>Why is skiplist?</h2><h3 id="预备知识"><a href="#预备知识" class="headerlink" title="预备知识"></a>预备知识</h3><h4 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h4><ul>
<li>优点<ul>
<li>插入和删除的时间复杂度都是O(1)</li>
<li>不需要分配连续的内存</li>
</ul>
</li>
<li>缺点<ul>
<li>查找时间复杂度为O(n) - 二分查找无法使用</li>
<li>无法跳跃到中间节点</li>
</ul>
</li>
</ul>
<h3 id="解释和分析"><a href="#解释和分析" class="headerlink" title="解释和分析"></a>解释和分析</h3><p>有了上述对链表的分析，我们可以知道，跳跃表就是继承了链表的所有优点而且改进了链表的所有缺点，是不是很神奇！</p>
<h2 id="What-is-skiplist"><a href="#What-is-skiplist" class="headerlink" title="What is skiplist?"></a>What is skiplist?</h2><h3 id="跳跃表性能"><a href="#跳跃表性能" class="headerlink" title="跳跃表性能"></a>跳跃表性能</h3><table>
<thead>
<tr>
<th align="center">算法</th>
<th align="center">Average</th>
<th align="center">Worst</th>
</tr>
</thead>
<tbody><tr>
<td align="center">空间</td>
<td align="center">O(n)</td>
<td align="center">O(nlogn)</td>
</tr>
<tr>
<td align="center">查找</td>
<td align="center">O(logn)</td>
<td align="center">O(n)</td>
</tr>
<tr>
<td align="center">插入</td>
<td align="center">O(logn)</td>
<td align="center">O(n)</td>
</tr>
<tr>
<td align="center">删除</td>
<td align="center">O(logn)</td>
<td align="center">O(n)</td>
</tr>
</tbody></table>
<blockquote>
<p>弄清楚查找类数据结构，主要是弄懂三个步骤，即<strong>查找、插入和删除</strong>的过程</p>
</blockquote>
<h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><p><a href="https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/skiplists.pdf" target="_blank" rel="noopener">[推荐看一下CMU的课件，清晰易懂]</a></p>
<p>skiplist的查找主要是利用了多层节点的方法，将普通的链表查找，转化为了二分查找，这样在牺牲空间复杂度的情况下，可以大大提升查找的效率。</p>
<p>假设查找的键用k来表示：</p>
<ul>
<li>如果 k = key, 那么查找完成</li>
<li>如果 k &lt; nextNode-&gt;key, 那么移动到下一级开始查找</li>
<li>如果 k &gt;= nextNode-&gt;key,那么继续向前查找</li>
</ul>
<h3 id="插入和删除"><a href="#插入和删除" class="headerlink" title="插入和删除"></a>插入和删除</h3><p><strong>根据“以往的经验”，比如红黑树在AVL树的基础上，将平衡性要求放松了，这样使得红黑树的插入和删除效率要高于AVL树</strong>。（红黑树要求从根到叶子的最长的可能路径不多于最短的可能路径的两倍长，AVL要求任意结点的孩子结点之间高度差距最大为1）</p>
<p>为了提升插入和删除的效率，跳表在层级的节点数处理上也对“结构化”降低也要求（完美的skiplist希望上层的节点数恰好是当前层的1/2，这样可以将二分查找的效率发挥到极致）。</p>
<p>skiplist降低要求的方法是：</p>
<ul>
<li>不要求每一层的节点恰好是前一层节点的一半，但是<strong>期望</strong>每一层节点的一半可以被分配到下一层</li>
</ul>
<p>看到<strong>期望</strong>这个词，不难猜出skiplist是一个基于概率的数据结构，这里才插入时决定层数的方法采用的是<strong>抛硬币法</strong></p>
<h4 id="插入新节点"><a href="#插入新节点" class="headerlink" title="插入新节点"></a>插入新节点</h4><ul>
<li>利用查找，缺点原链表的插入位置 O(logn)</li>
<li>把节点插入到原链表 O(1)</li>
<li>利用抛硬币的方式确定是否要将新节点提升到下一层，结果为“正”，则提升并继续抛硬币，结果为负则停止 O(logn)</li>
</ul>
<p>根据上面的之后可以看出，每一个节点都有1/2的概率被提升到上一层，那么根据<strong>期望</strong>，有1/2的节点会被提升到第一层（索引从0开始），有1/4的节点会被提升到第二层。</p>
<p>在Redis里面，抛硬币法的实现伪码如下<a href="https://juejin.im/post/57fa935b0e3dd90057c50fbc" target="_blank" rel="noopener">[Ref]</a>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">randomLevel()</span><br><span class="line">    level := <span class="number">1</span></span><br><span class="line">    <span class="comment">// random()返回一个[0...1)的随机数</span></span><br><span class="line">    <span class="keyword">while</span> random() &lt; p <span class="keyword">and</span> level &lt; MaxLevel <span class="keyword">do</span></span><br><span class="line">        level := level + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> level</span><br></pre></td></tr></table></figure>

<p>randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">p = <span class="number">1</span>/<span class="number">4</span></span><br><span class="line">MaxLevel = <span class="number">32</span></span><br></pre></td></tr></table></figure>

<p>由此可以计算skiplist每个节点的平均层数，也就是每个节点需要多少个“指针”</p>
<p><strong>删除节点</strong></p>
<p>删除操作，只需要找到节点，然后往下删除每一层相同节点即可。</p>
<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul>
<li>相比AVL树和红黑树，跳跃表的优点在于维持结构平衡的成本比较低，抛硬币法，完全依靠随机。而AVL和红黑树需要Rebalance来重新调整结构以达到平衡 （不过这是优点也是缺点，没有绝对的优劣，应用场景很重要）</li>
<li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。<strong>这点对于并发数据结构的实现也有好处，锁的粒度可以更小，或者说无锁也更容易实现</strong></li>
<li><a href="https://juejin.im/post/57fa935b0e3dd90057c50fbc" target="_blank" rel="noopener">[Ref]</a> 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</li>
</ul>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul>
<li>skiplist实际上是在用空间换时间，如果最高层为<em>n=*㏒(N)，那么占用的总结点数为 1 + *∑ⁿₒ</em> 2⁻ⁱ N ≈ 2N.</li>
<li><strong>防止缓存不命中</strong>，每一个节点的层全部用固定大小的数组来管理，这里可以避免在查找时，去到下一层时的缓存不命中 (这点有待商榷)</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]. <a href="https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/skiplists.pdf" target="_blank" rel="noopener">https://www.cs.cmu.edu/~ckingsf/bioinfo-lectures/skiplists.pdf</a></p>
<p>[2]. <a href="https://medium.com/@cxu29/skip-list-950105054f9d" target="_blank" rel="noopener">https://medium.com/@cxu29/skip-list-950105054f9d</a></p>
<p>[3]. <a href="https://stackoverflow.com/questions/256511/skip-list-vs-binary-search-tree" target="_blank" rel="noopener">https://stackoverflow.com/questions/256511/skip-list-vs-binary-search-tree</a></p>
<p>[4]. <a href="https://juejin.im/post/57fa935b0e3dd90057c50fbc" target="_blank" rel="noopener">https://juejin.im/post/57fa935b0e3dd90057c50fbc</a></p>
<p>[5]. <a href="https://zhuanlan.zhihu.com/p/53975333" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/53975333</a></p>
<p>[6]. <a href="http://ticki.github.io/blog/skip-lists-done-right/" target="_blank" rel="noopener">http://ticki.github.io/blog/skip-lists-done-right/</a></p>
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里KV引擎HotRing读后感</title>
    <url>/2020/05/12/HotRing%E8%AF%BB%E5%90%8E%E6%84%9F/</url>
    <content><![CDATA[<h1 id="HotRing"><a href="#HotRing" class="headerlink" title="HotRing"></a>HotRing</h1><blockquote>
<p>HotRing是Tair团队的创新性纯内存KV存储引擎设计。其引擎吞吐性能可达600M ops/s，与目前最快的KVS系统相比，可实现2.58倍的性能提升。HotRing最重要的创新点是：极大的提升了KVS引擎对于热点访问的承载能力。这对于KVS系统的稳定性以及成本控制尤为关键。</p>
</blockquote>
<p>PS: 笔者能力有限，仅限于对这篇博大精深的文章提出部分<strong>自己的思考与总计</strong></p>
<a id="more"></a>

<h2 id="Techical-Points"><a href="#Techical-Points" class="headerlink" title="Techical Points"></a>Techical Points</h2><p>这里就HotRing比较NB的四个技术点之三来谈点自己的感想</p>
<h3 id="有序环"><a href="#有序环" class="headerlink" title="有序环"></a>有序环</h3><p>在哈希表头结点对应的数据结构的实现上，采用了有序环，相比传统的链式哈希索引，有两个特点： 有序和环。重点来了，接下来将会分析为什么这两种的组合会是热点动态调整的最优选择！</p>
<blockquote>
<p>为什么必须设置成环状？</p>
</blockquote>
<p>环状 为什么必须是环状？因为热点是动态变化，所以头指针会动态移动，这里需要 保证无论头指针移动到链表中的哪一个结点，都要能遍历整个链表，所以必须 设置成环状，当然设置成双向链表也可以，但是，环状只需将尾结点的指针指 向头结点即可，相比双向链表，显然环状链表内存开销更小，性能更优。</p>
<blockquote>
<p>为什么要选择有序？</p>
</blockquote>
<p>有序有两个原因：（1）如果环不是有序，那么当一个read miss操作遍历冲突环的话，它会形成死循环，一直无法查找到缓存。（2）有序可以减少查找次数，提升性能 </p>
<blockquote>
<p>除了有序环还有其它选择吗？</p>
</blockquote>
<p> 对于有序环可以优化查找热点的次数，对于有序结构有没有更好的选择呢？据笔者了解，查找性能高的数据结构有：<strong>红黑树</strong>或者<strong>AVL树</strong>、还有<strong>跳表</strong>等。那么这里可以选择一种用来替代有序环吗？<br><strong>先给结论：红黑树和AVL树不行，跳表可以（但相比有序环不一定会更优）</strong></p>
<ul>
<li>红黑树和AVL树在这里不能替代有序环的原因是，（1）除了考虑优化查找速 度，还要考虑如何优化调整热点（也就是发生哈希冲突时，哈希值对应的头结 点），显然用树结构在这里做查找，如果热点变化，也就是树的根结点发生变 化，试想如果把突然把深度大于3的节点调整为根节点，只能说臣妾真的做不到 啊！显然此时调整树的结构变的非常棘手，甚至行不通（2）另外不选择树的原因在于，在 并 发 状 态 下 ， 无 锁 链 表 的 实 现 比 树 的 无 锁 实 现 更 加 简 单 ， 而 且<a href="https://stackoverflow.com/questions/256511/skip-list-vs-binary-search-tree" target="_blank" rel="noopener">[StackOverflow高赞回答]</a>表明无锁红黑树并不存在，这意味着在此篇文章的场景下，使用有锁的红黑树在并发状态下的开销会比无锁链表更高（这里是就特定场景而言，并不是断言有锁的开销就比无锁大）。</li>
<li>跳跃表可以替代有序环，只要把跳跃表的每一层都改装成环状即可，虽然这种情况下优化了查找速度，但是占用的空间却比原来的有序环大，<strong>对于HotRing来说，取决于在空间和速度上的取舍，也许跳跃表真能优化性能</strong></li>
</ul>
<blockquote>
<p>回到最后，无序链表到底行不行 ?</p>
</blockquote>
<p>最后，有序环虽然相对于无序链表可以不用遍历整个冲突链，就能返回结果（是否存在热点），但是一般情况下，有序环也好不到哪去。根据论文的结果来看，有序环之所以能表现的很好，应该是有两个原因：第一，适应热点的动态调整设计使得热点往往会出现在或者靠近头结点，第二，HotRing利用访问所 需平均内存访问次数(access overhead)来替代传统rehash策略的负载因子(load factor)，这样可以保证每个链上存在的热点不会特别多。这里其实第一点也在成就第二点，动态调整使得不用过多的平均内存访问次数就可以获得热点。 </p>
<h3 id="热点动态"><a href="#热点动态" class="headerlink" title="热点动态"></a>热点动态</h3><p>调整 HotRing实现了两种策略来实现周期性的热点识别与调整。每R次访问为一个周期，第R次访问的线程将进行头指针的调整。两种策略如下： </p>
<ul>
<li>随机移动策略：每R次访问，移动头指针指向第R次访问的item。若已经指向该item，则头指针不移动。该策略的优势是，不需要额外的元数据开销，且不需要采样过程，响应速度极快</li>
<li>采样分析策略：每R次访问，尝试启动对应冲突环的采样，统计item的访问频率。若第R次访问的item已经是头指针指向的item，则不启动采样</li>
</ul>
<p>最后：对于这两种方式，其实日常也有接触，真正的能把简单的思想应用到复 杂的系统中才是真大佬啊！ </p>
<h3 id="无锁链表"><a href="#无锁链表" class="headerlink" title="无锁链表"></a>无锁链表</h3><p>无锁链表的实现，因为最近实在是太忙了，其实还是挺想放个代码的。这里给出一个自己实现的无锁队列的链接，其实整体思路应该差不多，就是利用CAS机制，不断去判断当前节点是否是自己获取到的节点，这里也给出无锁链表的论文，有兴趣的读者可以自己去看看.<a href="https://www.cl.cam.ac.uk/research/srg/netos/papers/2001-caslists.pdf" target="_blank" rel="noopener">[CMU论文]</a></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1]. Chen, Jiqiang, et al. “HotRing: A Hotspot-Aware In-Memory Key-Value Store.” <em>18th {USENIX} Conference on File and Storage Technologies ({FAST} 20)</em>. 2020.<br>[2]. <a href="https://zhuanlan.zhihu.com/p/112928251" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/112928251</a></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>redis读书笔记</title>
    <url>/2020/03/01/redis%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="浅析Redis"><a href="#浅析Redis" class="headerlink" title="浅析Redis"></a>浅析Redis</h1><p>本文主要是自己的思考以及《Redis设计与实现》的读书笔记！</p>
<a id="more"></a>

<h2 id="What-is-Redis"><a href="#What-is-Redis" class="headerlink" title="What is Redis?"></a>What is Redis?</h2><p>Redis -&gt; remote dictionary server，本质是一个Key-Value类型的内存数据库，可以用作数据库、缓存、消息中间件等</p>
<p>整个数据库统统加载在内存当中进行，定期通过异步操作把数据库数据保存在磁盘里面。因为是纯内存操作，使得Redis的性能非常出色</p>
<h3 id="Redis的特点"><a href="#Redis的特点" class="headerlink" title="Redis的特点"></a>Redis的特点</h3><p>Redis作为一个内存数据库，有如下特点</p>
<ul>
<li>丰富的数据类型</li>
<li>支持数据持久化 （RDB和AOF）</li>
<li>复制、哨兵模式和集群</li>
</ul>
<h4 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h4><ul>
<li>读写全部在内存中，速度快</li>
<li>支持多种数据结构</li>
<li>单线程，不用担心竞争</li>
<li>特性丰富，支持持久化、复制、sentinel、集群等</li>
<li>支持事务，Redis的所有操作都是原子性的，同时Redis还支持对几个操作合并后的原子性执行</li>
</ul>
<p>相比于其它数据库，</p>
<h4 id="劣势"><a href="#劣势" class="headerlink" title="劣势"></a>劣势</h4><ul>
<li>数据库容量受到物理内存的限制，不能用作海量数据的高性能读写，因此Redis适合的场景主要局限在较小数据量的高性能操作和运算上</li>
<li>Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复</li>
<li>主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性</li>
<li>Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费</li>
</ul>
<h3 id="Redis为什么这么快"><a href="#Redis为什么这么快" class="headerlink" title="Redis为什么这么快"></a>Redis为什么这么快</h3><ul>
<li>采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗</li>
<li>完全基于内存，绝大部分请求是纯粹的内存操作，非常快速</li>
<li>数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的</li>
<li>使用多路 I/O 复用模型，非阻塞 IO</li>
<li>todo使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis 直接自己构建了 VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求</li>
</ul>
<h3 id="Redis高可用-3"><a href="#Redis高可用-3" class="headerlink" title="Redis高可用[3]"></a>Redis高可用<a href="https://juejin.im/post/5b7d226a6fb9a01a1e01ff64" target="_blank" rel="noopener">[3]</a></h3><p>在 <code>Redis</code> 中，实现 <strong>高可用</strong> 的技术主要包括 <strong>持久化</strong>、<strong>复制</strong>、<strong>哨兵</strong> 和 <strong>集群</strong>，下面简单说明它们的作用，以及解决了什么样的问题：</p>
<ul>
<li><strong>持久化</strong>：持久化是 <strong>最简单的</strong> 高可用方法。它的主要作用是 <strong>数据备份</strong>，即将数据存储在 <strong>硬盘</strong>，保证数据不会因进程退出而丢失。</li>
<li><strong>复制</strong>：复制是高可用 <code>Redis</code> 的基础，<strong>哨兵</strong> 和 <strong>集群</strong> 都是在 <strong>复制基础</strong> 上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。</li>
<li><strong>哨兵</strong>：在复制的基础上，哨兵实现了 <strong>自动化</strong> 的 <strong>故障恢复</strong>。缺陷是 <strong>写操作</strong> 无法 <strong>负载均衡</strong>，<strong>存储能力</strong> 受到 <strong>单机</strong> 的限制。</li>
<li><strong>集群</strong>：通过集群，<code>Redis</code> 解决了 <strong>写操作</strong> 无法 <strong>负载均衡</strong> 以及 <strong>存储能力</strong> 受到 <strong>单机限制</strong> 的问题，实现了较为 <strong>完善</strong> 的 <strong>高可用方案</strong>。</li>
</ul>
<h2 id="数据结构与对象"><a href="#数据结构与对象" class="headerlink" title="数据结构与对象"></a>数据结构与对象</h2><h2 id="事件"><a href="#事件" class="headerlink" title="事件"></a>事件</h2><ul>
<li>Redis 服务器是一个事件驱动程序， 服务器处理的事件分为时间事件和文件事件两类。</li>
<li>文件事件处理器是基于 Reactor 模式实现的网络通讯程序。</li>
<li>文件事件是对套接字操作的抽象： 每次套接字变得可应答（acceptable）、可写（writable）或者可读（readable）时， 相应的文件事件就会产生。</li>
<li>文件事件分为 <code>AE_READABLE</code> 事件（读事件）和 <code>AE_WRITABLE</code> 事件（写事件）两类。</li>
<li>时间事件分为定时事件和周期性事件： 定时事件只在指定的时间达到一次， 而周期性事件则每隔一段时间到达一次。</li>
<li>服务器在一般情况下只执行 <code>serverCron</code> 函数一个时间事件， 并且这个事件是周期性事件。</li>
<li>文件事件和时间事件之间是合作关系， 服务器会轮流处理这两种事件， 并且处理事件的过程中也不会进行抢占。</li>
<li>时间事件的实际处理时间通常会比设定的到达时间晚一些</li>
</ul>
<h2 id="数据库操作"><a href="#数据库操作" class="headerlink" title="数据库操作"></a>数据库操作</h2><h4 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h4><p>redis 过期策略是：定期删除+惰性删除</p>
<ul>
<li><p>定期删除</p>
<p>每隔一段时间主动查找并删除过期键</p>
<p>redis 默认是每隔 100ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除</p>
</li>
<li><p>惰性删除</p>
<p>只在碰到过期键时才进行删除操作</p>
<p>在你获取某个 key 的时候，redis 会检查一下 ，这个 key 如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西</p>
</li>
</ul>
<p>Redis摒弃了定时删除</p>
<h3 id="缓存淘汰策略"><a href="#缓存淘汰策略" class="headerlink" title="缓存淘汰策略"></a>缓存淘汰策略</h3><ul>
<li>noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了</li>
<li>allkeys-lru：当内存不足以容纳新写入数据时，<strong>在键空间中</strong>，移除最近最少使用的 key<strong>（这个是最常用的）</strong> LRU</li>
<li>allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊</li>
<li>volatile-lru：当内存不足以容纳新写入数据时，在<strong>设置了过期时间的键空间中</strong>，移除最近最少使用的 key<strong>（这个一般不太合适）</strong></li>
<li>volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key</li>
<li>volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除</li>
</ul>
<h2 id="持久化方案及基本原理"><a href="#持久化方案及基本原理" class="headerlink" title="持久化方案及基本原理"></a>持久化方案及基本原理</h2><p><strong>Redis为了保证效率，将数据缓存在了内存中，但是会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件中，以保证数据的持久化。</strong>如果不把储存在内存中的数据库状态保存到磁盘里面，那么一旦服务器进程退出，服务器中的数据库状态也会消失不见</p>
<p><strong>Redis的持久化策略</strong></p>
<ul>
<li>RBD:  (RDB is for Redis Database Backup file) 通过快照直接把内存中的数据保存到一个dump文件中，所以即使Redis服务器进程退出，但只要RDB文件存在，Redis服务器就可以用它来还原数据库状态</li>
<li>AOF: AOF持久化通过保存Redis服务器所执行的写命令来记录数据库的状态</li>
</ul>
<h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>默认Redis是会以快照“RDB”的形式将数据持久化到磁盘的一个二进制文件dump.rdb.  <strong>RDB持久化是通过保存数据库中的键值对来记录数据库状态的</strong></p>
<h5 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h5><p>RDB生成有两种办法SAVE和BGSAVE</p>
<ul>
<li>SAVE命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在服务器进程阻塞期间，服务器不能处理任何命令请求</li>
<li>BGSAVE命令会fork出一个子进程，然后由子进程负责创建RDB文件，服务器进程（父进程）继续处理命令请求</li>
</ul>
<p>Note：<strong>Redis在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件</strong>。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。</p>
<p>在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的RDB文件中，因此，数据库中包含过期键不会对生成新的RDB文件造成影响</p>
<h5 id="优缺点分析"><a href="#优缺点分析" class="headerlink" title="优缺点分析"></a>优缺点分析</h5><p><strong>优点</strong></p>
<ul>
<li>通过创建一个子进程的方法将Redis 的内存数据保存到硬盘中，因此，它并不会对 Redis 服务器性能造成多大的影响</li>
<li>非常适用于定时备份和定期备份，服务器遇到问题时可以将数据集还原到不同的版本</li>
</ul>
<p><strong>缺点</strong></p>
<ul>
<li><a href="https://blog.csdn.net/lihao21/article/details/74859707" target="_blank" rel="noopener">[Ref]</a> 尽管快照持久化允许 Redis 恢复到快照文件的状态，但如果 RDB 文件生成后，Redis 服务器继续处理了写命令导致 Redis 内存数据有更新，这时恰好 Redis 崩溃了而来不及保存新的 RDB 文件，那么 Redis 将会丢失这部分新的数据。也就是说，如果系统真的发生崩溃，那么我们将会丢失最近一次生成 RDB 文件之后更改的所有数据。因此，<strong>快照持久化方法只适用于那些即使丢失一部分数据也不会造成问题的应用场景</strong>。</li>
<li>快照持久化方法需要调用<code>fork()</code>方法创建子进程。当 Redis 内存的数据量较大时，创建子进程和生成 RDB 文件得占用较多的系统资源和处理时间，这会对 Redis 正常处理客户端命令的性能造成较大的影响。</li>
</ul>
<h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><h5 id="工作原理-1"><a href="#工作原理-1" class="headerlink" title="工作原理"></a>工作原理</h5><p>与RDB持久化通过保存数据库中的键值对来记录数据库状态不同，<strong>AOF持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的</strong></p>
<p><strong>AOF持久化功能的实现可以分为命令追加、文件写入和文件同步三个步骤</strong></p>
<h6 id="命令追加"><a href="#命令追加" class="headerlink" title="命令追加"></a>命令追加</h6><p>当AOF持久化功能处于打开状态时，服务器在执行完一个写命令之后，会以协议格式将被执行的写命令追加到服务器状态的aof_buf缓冲区的末尾</p>
<h6 id="文件写入与同步"><a href="#文件写入与同步" class="headerlink" title="文件写入与同步"></a>文件写入与同步</h6><p>因为服务器在处理文件事件时可能会执行写命令， 使得一些内容被追加到 <code>aof_buf</code> 缓冲区里面， 所以在服务器每次结束一个事件循环之前， 它都会调用 <code>flushAppendOnlyFile</code> 函数， 考虑是否需要将 <code>aof_buf</code> 缓冲区中的内容写入和保存到 AOF 文件里面</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">eventLoop</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 处理文件事件，接收命令请求以及发送命令回复</span></span><br><span class="line">        <span class="comment"># 处理命令请求时可能会有新内容被追加到 aof_buf 缓冲区中</span></span><br><span class="line">        processFileEvents()</span><br><span class="line">        <span class="comment"># 处理时间事件</span></span><br><span class="line">        processTimeEvents()</span><br><span class="line">        <span class="comment"># 考虑是否要将 aof_buf 中的内容写入和保存到 AOF 文件里面</span></span><br><span class="line">        flushAppendOnlyFile()</span><br></pre></td></tr></table></figure>

<p><code>flushAppendOnlyFile</code> 函数的行为由服务器配置的 <code>appendfsync</code> 选项的值来决定， 如果用户没有主动为 <code>appendfsync</code> 选项设置值， 那么 <code>appendfsync</code> 选项的默认值为 <code>everysec</code>(将 <code>aof_buf</code> 缓冲区中的所有内容写入到 AOF 文件， <strong>如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是由一个线程专门负责执行的</strong>)</p>
<blockquote>
<p>文件的写入和同步</p>
<p>为了提高文件的写入效率， 在现代操作系统中， 当用户调用 <code>write</code> 函数， 将一些数据写入到文件的时候， 操作系统通常会将写入数据暂时保存在一个内存缓冲区里面， 等到缓冲区的空间被填满、或者超过了指定的时限之后， 才真正地将缓冲区中的数据写入到磁盘里面。</p>
<p>这种做法虽然提高了效率， 但也为写入数据带来了安全问题， 因为如果计算机发生停机， 那么保存在内存缓冲区里面的写入数据将会丢失。</p>
<p>为此， 系统提供了 <code>fsync</code> 和 <code>fdatasync</code> 两个同步函数， 它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面， 从而确保写入数据的安全性。</p>
</blockquote>
<h6 id="AOF文件重写"><a href="#AOF文件重写" class="headerlink" title="AOF文件重写"></a>AOF文件重写</h6><p>Redis提供AOF文件重写功能主要是为了解决AOF文件体积膨胀的问题，通过该功能，Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，新旧两个AOF文件所保存的数据库状态相同，但新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积小很多。</p>
<p><strong>AOF重写实现原理</strong>：<strong>首先从数据库中读取键现在的值，然后用一条命令去记录键值对代替之前记录键值对的多条命令</strong>，新AOF文件不会包含任何浪费空间的冗余命令，所以新AOF文件的体积通常会比旧AOF文件的体积小很多。重写程序在处理列表、哈希表、集合和有序集合则四种可能会带有多个元素的键时，会检查键所包含的元素的个数，如果元素的数量超过了设定常量的值，那么重写程序会使用多条命令来记录键的值，而不是单使用一条命令</p>
<h6 id="AOF后台重写"><a href="#AOF后台重写" class="headerlink" title="AOF后台重写"></a>AOF后台重写</h6><p>因为Redis使用单个线程处理请求，为防止服务器进程阻塞（服务器无法处理客户端发来的命令请求），所以Redis将AOF重写放到子进程执行，这样由两个好处</p>
<ol>
<li>子进程执行AOF重写期间，服务器进程（父进程）可以继续处理命令请求</li>
<li><strong>子进程带有服务器进程的数据副本，使用子进程而不是线程，可以避免使用锁的情况下，保证数据的安全性</strong></li>
</ol>
<p><strong>基本思路</strong></p>
<ul>
<li>重写会有大量的写入操作，所以服务器进程会<code>fork</code>一个子进程来创建一个新的AOF文件</li>
<li>在重写期间，服务器进程继续处理命令请求，如果有写入的命令，会造成重写后的AOF文件和服务器当前的数据库状态不一致的问题，为了解决这种数据不一致的问题，Redis服务器设置了一个AOF重写缓冲区，在有新的吸入命令到达时，追加到<code>aof_buf</code>的同时，还会追加到<code>aof_rewrite_buf</code>AOF重写缓冲区。当子进程完成重写之后，会给父进程一个信号，然后父进程会把AOF重写缓冲区的内容写进新的AOF临时文件中，再对新的AOF文件改名完成替换，这样可以保证新的AOF文件与当前数据库数据的一致性。</li>
</ul>
<p><strong>以下是后台重写 AOF 文件（BGREWRITEAOF）的工作步骤：</strong></p>
<p>1) 用户调用 BGREWRITEAOF</p>
<p>2) Redis 调用这个函数，它执行 fork() ：<br>    2a)子进程在临时文件中对 AOF 文件进行重写<br>    2b)父进程将新输入的写命令追加到 server.aof_rewrite_buf 中</p>
<p>3) 当步骤 2a 执行完之后，子进程结束</p>
<p>4) 父进程会捕捉子进程的退出信号，如果子进程的退出状态是 OK 的话，那么父进程将新输入命令的缓存追加到临时文件，然后使用 rename(2) 对临时文件改名，用它代替旧的 AOF 文件，至此，后台 AOF 重写完成。</p>
<p><strong>关于如何替代旧的AOF文件</strong></p>
<p><a href="https://github.com/huangz1990/redis-3.0-annotated/blob/unstable/src/aof.c" target="_blank" rel="noopener">todo</a></p>
<h5 id="优缺点分析-1"><a href="#优缺点分析-1" class="headerlink" title="优缺点分析"></a>优缺点分析</h5><p><strong>优点</strong></p>
<p>AOF 让 Redis 变得非常耐久。通过同步策略控制，可以尽可能地减少AOF丢失的命令数据。AOF的默认策略是每秒钟 Fsync 一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据</p>
<p><strong>缺点</strong></p>
<p>AOF 的文件体积通常要大于 RDB 文件的体积。根据所使用的 Fsync 策略，AOF 的速度可能会慢于 RDB</p>
<h4 id="两种持久化方式对比"><a href="#两种持久化方式对比" class="headerlink" title="两种持久化方式对比"></a>两种持久化方式对比</h4><ul>
<li><p>Redis 支持同时开启 RDB 和 AOF，系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。</p>
</li>
<li><p>AOF 将 Redis 执行的每一条命令都实时的追加到磁盘中，处理大量的写入会降低Redis的性能，如果能接受AOF带来的性能损失，可以选择AOF持久化</p>
</li>
<li><p>RDB是定时做备份，如果能够接受定时的时间间隔内的数据丢失，那么可以选择RDB持久</p>
</li>
<li><p>RDB文件是定时生成的，非常便于数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度快。（AOF文件需要重新执行一遍指令）</p>
</li>
</ul>
<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>在Redis中，从服务器对主服务器的更换可以分为以下两种情况：</p>
<ul>
<li><strong>初次复制</strong>：从服务器没有复制过当前的主服务器</li>
<li><strong>断线后重复制</strong>：处于命令传播阶段的主从服务器因为网络问题而中断复制，从服务器通过自动重连，重新连接上主服务器并继续复制。</li>
</ul>
<p>Redis新版的复制功能：PSYNC命令具有完整重同步和部分重同步两种模式：</p>
<ul>
<li><strong>完整重同步用于处理初次复制情况</strong>：他们是通过让主服务器创建并发送RDB文件，以及向从服务器发送保存在缓冲区里面的写命令进行同步的</li>
<li><strong>部分重同步用于处理断线后的重复制情况</strong>：（PS：因为断线之后复制，只是为了弥补断线期间缺失的一小部分数据，实施完整重同步的做法是非常低效的）当从服务器断线后重新连接主服务器时，如果条件允许，主服务器可以将从服务器连接断开期间执行的写命令发送给从服务器，从服务器只要接受并执行这些写命令，就可以将数据库更新至主服务器当前所处的状态</li>
</ul>
<h3 id="复制功能的原理"><a href="#复制功能的原理" class="headerlink" title="复制功能的原理"></a>复制功能的原理</h3><p>Redis的复制功能分为同步和命令传播两个操作</p>
<ul>
<li>同步操作用于将从服务器的数据库状态更新至主服务器当前所处的状态</li>
<li>而命令传播操作则用于在主服务器的数据库状态被修改， 导致主从服务器的数据库状态出现不一致时， 让主从服务器的数据库重新回到一致状态。</li>
</ul>
<h4 id="同步"><a href="#同步" class="headerlink" title="同步"></a>同步</h4><h5 id="完整重同步"><a href="#完整重同步" class="headerlink" title="完整重同步"></a>完整重同步</h5><ol>
<li>从向主发送SYNC命令</li>
<li>主收到命令后执行BGSAVE，在后台生成RDB文件，并使用一个缓冲区记录从执行BGSAVE开始执行的所有写命令</li>
<li>当主的BGSAVE命令执行完毕时，主会将BGSAVE在后台生成的RDB文件发送给从服务器，从服务器接收并载入这个 RDB 文件， 将自己的数据库状态更新至主服务器执行 BGSAVE 命令时的数据库状态。</li>
<li>主服务器将记录在缓冲区里面的所有写命令发送给从服务器， 从服务器执行这些写命令， 将自己的数据库状态更新至主服务器数据库当前所处的状态。</li>
</ol>
<h5 id="部分重同步"><a href="#部分重同步" class="headerlink" title="部分重同步"></a>部分重同步</h5><p>部分重同步功能由以下三个部分构成：</p>
<ul>
<li>主服务器的<strong>复制偏移量</strong>（replication offset）和从服务器的复制偏移量</li>
<li><strong>主服务器的复制积压缓冲区（replication backlog）</strong></li>
<li><strong>服务器的运行ID</strong>（run ID）</li>
</ul>
<h6 id="复制偏移量"><a href="#复制偏移量" class="headerlink" title="复制偏移量"></a>复制偏移量</h6><p>执行复制的双方—主服务器和从服务器会分别维护一个复制偏移量：</p>
<ul>
<li>主服务器每次向从服务器传播N个字节的数据时，就将自己的复制偏移量的值加上N</li>
<li>从服务器每次收到主服务器传播来的N个字节的数据时，就将自己的复制偏移量的值加上N</li>
</ul>
<p><strong>通过对比主从服务器的复制偏移量，程序可以很容易地知道主从服务器是否处于一致状态</strong>：</p>
<ul>
<li>如果主从服务器处于一致状态，那么主从服务器两者的偏移量总是相同的</li>
<li>相反，如果主从服务器两者的偏移量并不相同，那么说明主从服务器并未处于一致状态</li>
</ul>
<blockquote>
<p>从服务器A在断线之后就立即重新连接主服务器，并且成功，那么接下来，<strong>从服务器将向主服务器发送PSYNC命令</strong>，并报告自己的偏移量，<strong>主服务器将根据偏移量和复制积压缓冲区决定执行完整重同步还是部分重同步</strong></p>
</blockquote>
<h6 id="复制积压缓冲区"><a href="#复制积压缓冲区" class="headerlink" title="复制积压缓冲区"></a>复制积压缓冲区</h6><p>复制积压缓冲区是由主服务器维护的一个固定长度（fixed-size）先进先出（FIFO）队列，默认大小为1MB。</p>
<p><strong>当主服务器进行命令传播时，它不仅会将写命令发送给所有从服务器，还会将写命令入队到复制积压缓冲区里面</strong>。因此，主服务器的复制积压缓冲区里面会保存着一部分最近传播的写命令，并且复制积压缓冲区会为队列中的每个字节记录相应的复制偏移量</p>
<p>当从服务器重新连上主服务器时，从服务器会通过PSYNC命令将自己的复制偏移量offset发送给主服务器，主服务器会根据这个复制偏移量来决定对从服务器执行何种同步操作：</p>
<ul>
<li>如果offset偏移量之后的数据（也即是偏移量offset+1开始的数据）仍然存在于复制积压缓冲区里面，那么主服务器将对从服务器执行部分重同步操作；</li>
<li>相反，如果offset偏移量之后的数据已经不存在于复制积压缓冲区，那么主服务器将对从服务器执行完整重同步操作。</li>
</ul>
<p><strong>关于缓冲区大小设置</strong></p>
<p>如果主服务器平均每秒产生1 MB的写数据，而从服务器断线之后平均要5秒才能重新连接上主服务器，那么复制积压缓冲区的大小就不能低于5MB。为了安全起见，可以将复制积压缓冲区的大小设为2*second*write_size_per_second，这样可以保证绝大部分断线情况都能用部分重同步来处理</p>
<h6 id="服务器运行ID"><a href="#服务器运行ID" class="headerlink" title="服务器运行ID"></a>服务器运行ID</h6><p>除了复制偏移量和复制积压缓冲区之外，实现部分重同步还需要用到服务器运行ID（run ID）:</p>
<ul>
<li>每个Redis服务器，<strong>不论主服务器还是从服务，都会有自己的运行ID</strong>；</li>
<li>运行ID在服务器启动时自动生成，由40个随机的十六进制字符组成，例如53b9b28df8042fdc9ab5e3fcbbbabff1d5dce2b — <a href="https://juejin.im/post/5b3a23746fb9a024e15cad79#heading-11" target="_blank" rel="noopener">[分布式唯一ID生成的集中方案]</a></li>
</ul>
<p>当从服务器对主服务器进行初次复制时，主服务器会将自己的运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来（注意哦，是<strong>从服务器保存了主服务器的ID</strong>），当从服务器断线并重新连上一个主服务器时，<strong>从服务器将向当前连接的主服务器发送之前保存的运行ID</strong>：</p>
<ul>
<li>如果从服务器保存的运行ID和当前连接的主服务器的运行ID相同，那么说明从服务器断线之前复制的就是当前连接的这个主服务器，主服务器可以继续尝试执行部分重同步操作；</li>
<li>相反地，如果从服务器保存的运行ID和当前连接的主服务器的运行ID并不相同，那么说明从服务器断线之前复制的主服务器并不是当前连接的这个主服务器，主服务器将对从服务器执行完整重同步操作。</li>
</ul>
<h4 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h4><p>在同步操作执行完毕之后， 主从服务器两者的数据库将达到一致状态， 但这种一致并不是一成不变的 —— <strong>每当主服务器执行客户端发送的写命令时， 主服务器的数据库就有可能会被修改， 并导致主从服务器状态不再一致</strong>。</p>
<p>为了让主从服务器再次回到一致状态， 主服务器需要对从服务器执行命令传播操作： 主服务器会将自己执行的写命令 —— 也即是造成主从服务器不一致的那条写命令 —— 发送给从服务器执行， 当从服务器执行了相同的写命令之后， 主从服务器将再次回到一致状态。</p>
<h3 id="复制功能的实现"><a href="#复制功能的实现" class="headerlink" title="复制功能的实现"></a>复制功能的实现</h3><p>有六个步骤：（1）设置主服务器的地址和端口；（2）建立套接字连接；（3）发送PING命令；（4）身份验证；（5）发送端口信息；（6）同步；（7）命令传播</p>
<p>下面将对这六个步骤展开讲述：</p>
<ol>
<li><p>步骤一：设置主服务器的地址和端口</p>
</li>
<li><p>步骤二：建立套接字连接</p>
</li>
<li><p>步骤三：发送PING命令</p>
<p>这个PING命令主要是为了：</p>
<ul>
<li>通过发送PING命令检查套接字的读写状态</li>
<li>通过PING命令可以检查主服务器能否正常处理命令</li>
</ul>
<p>从服务器在发送PING命令之后可能遇到以下三种情况：</p>
<ul>
<li>主服务器向从服务器返回了一个命令回复，但从服务器却不能在规定的时限内读取命令回复的内容(timeout)，说明网络连接状态不佳，从服务器将断开并重新创建连向主服务器的套接字</li>
<li>如果主服务器返回一个错误，那么表示主服务器暂时没有办法处理从服务器的命令请求，从服务器也将断开并重新创建连向主服务器的套接字</li>
<li>如果从服务器读取到”PONG”回复，那么表示主从服务器之间的网络连接状态正常，那就继续执行下面的复制步骤</li>
</ul>
</li>
<li><p>步骤四：身份验证</p>
</li>
</ol>
<p><img src="https://images0.cnblogs.com/blog2015/754165/201508/111612480989940.png" alt="img"></p>
<ol start="5">
<li><p>步骤五：发送端口信息</p>
<p>slave_listening_port属性目前唯一的作用就是在主服务器执行INFO replication命令时打印出从服务器的端口号（貌似暂时作用不大）</p>
</li>
<li><p>步骤六：同步</p>
<p>在这一步，从服务器将向主服务器发送PSYNC命令，执行同步操作，并将自己的数据库更新至主服务器数据库当前所处的状态</p>
<p>需要注意的是在执行同步操作前，<strong>只有从服务器是主服务器的客户端。但是执行从不操作之后，主服务器也会称为从服务器的客户端</strong>：</p>
<ul>
<li>如果PSYNC命令执行的是完整同步操作，那么主服务器只有成为了从服务器的客户端才能将保存在<strong>缓冲区中的写命令</strong>发送给从服务器执行</li>
<li>如果PSYNC命令执行的是部分同步操作，那么主服务器只有成为了从服务器的客户端才能将保存在<strong>复制积压缓冲区中的写命令</strong>发送给从服务器执行</li>
</ul>
</li>
<li><p>步骤七：命令传播</p>
<p>当完成了同步之后，主从服务器就会进入命令传播阶段，这时主服务器只要一直将自己执行的写命令发送给从服务器，而从服务器只要一直接收并执行主服务器发来的写命令，就可以保证主从服务器一直保持一致了</p>
</li>
</ol>
<h3 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a>心跳检测</h3><p>在命令传播阶段，从服务器默认会以<strong>每秒一次的频率</strong>，向主服务器发送命令：<strong>REPLCONF ACK <replication_offset></strong>，其中replication_offset是从服务器当前的复制偏移量</p>
<p>发送REPLCONF ACK命令对于主从服务器有三个作用：</p>
<ul>
<li>检测主从服务器的网络连接状态</li>
<li>辅助实现min-slaves选项</li>
<li><strong>检测命令丢失</strong></li>
</ul>
<h4 id="检测主从服务器的网络连接状态"><a href="#检测主从服务器的网络连接状态" class="headerlink" title="检测主从服务器的网络连接状态"></a>检测主从服务器的网络连接状态</h4><p><strong>如果主服务器超过一秒钟没有收到从服务器发来的REPLCONF ACK命令，那么主服务器就知道主从服务器之间的连接出现问题了</strong>。</p>
<p>通过向主服务器发送<strong>INFO replication命令</strong>，在列出的从服务器列表的lag一栏中，我们可以看到相应从服务器最后一次向主服务器发送REPLCONF ACK命令距离现在过了多少秒</p>
<h4 id="辅助实现min-slaves选项"><a href="#辅助实现min-slaves选项" class="headerlink" title="辅助实现min-slaves选项"></a>辅助实现min-slaves选项</h4><p>Redis的<strong>min-slaves-to-write</strong>和<strong>min-slaves-max-lag</strong>两个选项可以<strong>防止主服务器在不安全的情况下执行写命令。</strong></p>
<p>举个例子，如果我们向主服务器提供以下设置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">min-slaves-to-write 3</span><br><span class="line">min-slaves-max-lag 10</span><br></pre></td></tr></table></figure>

<p>那么在<strong>从服务器的数量少于3个，或者三个从服务器的延迟（lag）值都大于或等于10秒时</strong>，主服务器将拒绝执行写命令，这里的延迟值就是上面提到的INFO replication命令的lag值</p>
<h4 id="检测命令丢失"><a href="#检测命令丢失" class="headerlink" title="检测命令丢失"></a>检测命令丢失</h4><p>我们从命令：REPLCONF ACK <replication_offset>就可以知道，每发送一次这个命令从服务器都会向主服务器报告一次自己的复制偏移量。如果因为网络故障，主服务器传播给从服务器的写命令在半路丢失，那么通过这个ACK可以检测是否由丢失</p>
<p>当主服务器发觉从服务器当前的复制偏移量少于自己的复制偏移量，<strong>然后主服务器就会根据从服务器提交的复制偏移量，在复制积压缓冲区里面找到从服务器缺少的数据</strong>，并将这些数据重新发送给从服务器</p>
<p>Note：主服务器向从服务器补发缺失数据的原理和部分重同步的原理非常相似，它们的区别在于：补发缺失数据操作在主从服务器没有断线的情况下执行，而部分重同步操作则在主从服务器断线并重连之后执行。</p>
<h3 id="主从复制优缺点"><a href="#主从复制优缺点" class="headerlink" title="主从复制优缺点"></a>主从复制优缺点</h3><blockquote>
<p>想了解一样东西的时候，必须明白它的优缺点</p>
</blockquote>
<p><a href="https://juejin.im/post/5b7d226a6fb9a01a1e01ff64" target="_blank" rel="noopener">[Reference]</a></p>
<h4 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h4><p><code>Redis</code> <strong>主从复制</strong> 可将 <strong>主节点</strong> 数据同步给 <strong>从节点</strong>，从节点此时有两个作用：</p>
<ol>
<li>一旦 <strong>主节点宕机</strong>，<strong>从节点</strong> 作为 <strong>主节点</strong> 的 <strong>备份</strong> 可以随时顶上来。</li>
<li>扩展 <strong>主节点</strong> 的 <strong>读能力</strong>，分担主节点读压力。</li>
</ol>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p><strong>主从复制</strong> 同时存在以下几个问题：</p>
<ol>
<li>一旦 <strong>主节点宕机</strong>，<strong>从节点</strong> 晋升成 <strong>主节点</strong>，同时需要修改 <strong>应用方</strong> 的 <strong>主节点地址</strong>，还需要命令所有 <strong>从节点</strong> 去 <strong>复制</strong> 新的主节点，整个过程需要 <strong>人工干预</strong></li>
<li><strong>主节点</strong> 的 <strong>写能力</strong> 受到 <strong>单机的限制</strong></li>
<li><strong>主节点</strong> 的 <strong>存储能力</strong> 受到 <strong>单机的限制</strong></li>
<li><strong>原生复制</strong> 的弊端在早期的版本中也会比较突出，比如：<code>Redis</code> <strong>复制中断</strong> 后，<strong>从节点</strong> 会发起 <code>psync</code>。此时如果 <strong>同步不成功</strong>，则会进行 <strong>全量同步</strong>，<strong>主库</strong> 执行 <strong>全量备份</strong> 的同时，可能会造成毫秒或秒级的 <strong>卡顿</strong></li>
</ol>
<h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><p><a href="https://juejin.im/post/5b7d226a6fb9a01a1e01ff64" target="_blank" rel="noopener">[值得仔细阅读]</a></p>
<h3 id="主要功能"><a href="#主要功能" class="headerlink" title="主要功能"></a>主要功能</h3><p>Redis Sentinel（哨兵）主要功能包括主节点存活检测、主从运行情况检测、自动故障转移、主从切换。Redis Sentinel 最小配置是一主一从</p>
<p>Redis 的 Sentinel 系统可以用来管理多个 Redis 服务器，该系统可以执行以下四个任务：</p>
<ol>
<li><p>监控</p>
<p>Sentinel会不断的检查主服务器和从服务器是否正常运行</p>
</li>
<li><p>通知</p>
<p>当被监控的某个 Redis 服务器出现问题，Sentinel 通过 API 脚本向管理员或者其他应用程序发出通知</p>
</li>
<li><p>自动故障转移</p>
<p>当 <strong>主节点</strong> 不能正常工作时，<code>Sentinel</code> 会开始一次 <strong>自动的</strong> 故障转移操作，它会将与 <strong>失效主节点</strong> 是 <strong>主从关系</strong> 的其中一个 <strong>从节点</strong> 升级为新的 <strong>主节点</strong>，并且将其他的 <strong>从节点</strong> 指向 <strong>新的主节点</strong></p>
</li>
<li><p>配置提供者</p>
<p>在 <code>Redis Sentinel</code> 模式下，<strong>客户端应用</strong> 在初始化时连接的是 <code>Sentinel</code> <strong>节点集合</strong>，从中获取 <strong>主节点</strong> 的信息。</p>
</li>
</ol>
<h3 id="工作原理-2"><a href="#工作原理-2" class="headerlink" title="工作原理"></a>工作原理</h3><h4 id="哨兵准备工作"><a href="#哨兵准备工作" class="headerlink" title="哨兵准备工作"></a>哨兵准备工作</h4><ol>
<li>启动并初始化 Sentinel</li>
<li>获取主服务器信息</li>
<li>获取从服务器信息</li>
<li>向主服务器和从服务器发送信息</li>
<li>接收来自主服务器和从服务器的频道信息</li>
</ol>
<h4 id="主要工作内容"><a href="#主要工作内容" class="headerlink" title="主要工作内容"></a>主要工作内容</h4><h5 id="检测主观下线状态"><a href="#检测主观下线状态" class="headerlink" title="检测主观下线状态"></a>检测主观下线状态</h5><p><strong>主观下线</strong> 适用于检测所有与它创建了命令连接的实例（包括主服务器、从服务器、其它Sentinel在内）。如果在 <code>down-after-milliseconds</code> 毫秒内，<code>Sentinel</code> 没有收到 <strong>目标节点</strong> 的有效回复，则会判定 <strong>该节点</strong> 为 <strong>主观下线</strong></p>
<p>在默认情况下，每个Sentinel以每秒钟一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其它Sentinel在内）发送一个PING命令，并通过实例返回的PING命令回复来判断实例是否在线</p>
<h5 id="检查客观下线状态"><a href="#检查客观下线状态" class="headerlink" title="检查客观下线状态"></a>检查客观下线状态</h5><p>当Sentinel将一个主服务器判断为主管下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这个服务器的其他Sentinel进行询问，看他们是否也认为该主服务器进入下线状态。<strong>当从其他Sentinel那里接收到足够数量已下线判断后，sentinel会将该主服务器判定为客观下线状态</strong></p>
<h5 id="选举领头-Sentinel"><a href="#选举领头-Sentinel" class="headerlink" title="选举领头 Sentinel"></a>选举领头 Sentinel</h5><p> Sentinel系统选举领头Sentinel的方法是对Raft算法的领头选举方法的实现</p>
<h5 id="故障转移"><a href="#故障转移" class="headerlink" title="故障转移"></a>故障转移</h5><p>在选举产生出领头Sentinel之后，领头Sentinel将对已下线的主服务器执行故障转移操作，该操作包含三个步骤：</p>
<ol>
<li>在已下线主服务器属下的所有从服务器里面，挑选出一个从服务器，并将其转换为主服务器 （挑选的规则可以看下）</li>
<li>让已下线主服务器属下的所有从服务器改为复制新的主服务器</li>
<li>已下线主服务器设置为新的主服务器的从服务器</li>
</ol>
<h2 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h2><p>Redis集群是Redis提供的分布式数据库方案，集群通过分片（sharding）来进行数据共享，并提供复制和故障转移功能</p>
<p>集群功能的实现主要由集群的节点、槽指派、命令执行、重新分片、转向、故障转移、消息等几个方面组成</p>
<h3 id="集群节点"><a href="#集群节点" class="headerlink" title="集群节点"></a>集群节点</h3><p>一个Redis集群通常由多个节点（node）组成，在刚开始的时候，每个节点都是相互独立的，它们都处于一个只包含自己的集群当中，要组建一个真正可工作的集群，我们必须将各个独立的节点连接起来，构成一个包含多个节点的集群</p>
<p>下图展示了节点握手过程，客户端通过向节点A发送CLUSTER MEET命令，<strong>可以让接收命令的节点A将另一个节点B添加到节点A当前所在的集群里面</strong>（这也就是握手过程）</p>
<p><img src="http://redisbook.com/_images/graphviz-76550f578052d5f52e35414facb5ac680d38c7f5.png" alt="Redisbook"></p>
<p>握手完成之后，节点A会将节点B的信息通过<strong>Gossip协议</strong>传播给集群中的其它节点，让其它节点也与节点B进行握手。最终，经过一段时间之后，节点B会被集群中的所有节点认识</p>
<h3 id="槽指派"><a href="#槽指派" class="headerlink" title="槽指派"></a>槽指派</h3><p><strong>Redis集群没有使用一致性hash,而是引入了哈希槽的概念</strong>，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模来决定放置哪个槽，集群的每个节点负责一部分hash槽</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算给定键key属于哪个槽</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">slot_number</span><span class="params">(key)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> CRC16(key) &amp; <span class="number">16383</span></span><br></pre></td></tr></table></figure>

<p><strong>Redis集群通过分片的方式来保存数据库的键值对</strong>：集群中的整个数据库被分为16384个槽（slot），数据库中的每个键都属于其中的一个，集群中的每个节点可以处理0个或最多16384个槽</p>
<p>当数据库中的16384个槽都有节点在处理时，集群处于上线状态（ok），<strong>如果任何一个槽都没有得到处理</strong>，就处于下线状态（fail）</p>
<p><strong>下面的内容主要介绍了保存槽指派信息的方法，以及节点之间传播槽指派信息的方法</strong></p>
<ol>
<li><p>记录节点的槽指派信息</p>
<p>通过索引i上的二进制位的值来判断节点是否负责处理槽i，所以取出和设置slots数组中的任意一个二进制位的值的复杂度仅为O(1)</p>
</li>
<li><p>传播节点的槽指派信息</p>
<p>一个节点除了会将自己负责处理的槽记录在<strong>clusterNode</strong>结构的slots属性和numslots属性之外，它还会将自己的slots数组通过消息发送给集群中的其他节点，来告知其他节点自己目前负责处理哪些槽。</p>
<p>因为集群中的每个节点都会将自己的slots数组通过消息发送给集群中的其他节点，并且每个接收到slots数组的节点都会将数组保存到相应节点的clusterNode结构里面，因此，集群中的每个节点都会知道数据库中的16384个槽分别被指派给了集群中的哪些节点。</p>
</li>
<li><p>记录集群所有槽的指派信息</p>
<p><strong>clusterState结构中也有一个slots数组，该数组记录了集群中所有16384个槽的指派信息，每个数组项都是一个指向clusterNode结构的指针.</strong> 注意clusterState是每一个节点都有的，且集群中的每个节点的clusterState中的slots数组都想同，从而使得节点能够互相知道哪个槽指派给了哪个节点</p>
<p>cluterNode针对自己，clusterState针对集群</p>
<ul>
<li>clusterState.slots数组记录了集群中所有槽的指派信息</li>
<li>clusterNode.slots数组只记录了clusterNode结构所代表的节点的槽指派信息，clusterNode.slots只能明白自己是否与负责某个槽</li>
<li>1 当为了检索槽i是否已经被指派，或者槽i被指派给了哪个节点，程序有两种方案：第一，遍历nodes字典，检查所有的clusterNode.slots，这个时间复杂度是O(N)，其中N为clusterNode的数量；第二，如果有clusterState.slots存在，则只需要通过索引i访问即可，这个操作时间复杂度是O(1)，显然clusterState<strong>有存在的必要</strong></li>
<li>clusterNode.slots存在的必要在于当程序需要将某个节点的槽指派信息发送给其他节点时可以直接使用clusterNode.slots数组信息</li>
</ul>
</li>
</ol>
<p>通过<code>CLUSTER ADDSLOTS</code>命令的将所有输入的槽指派给接收该命令的节点负责，最后在<code>CLUSTER ADDSLOTS</code>命令执行完毕之后，节点会通过发送消息告知集群中的其它节点，自己目前正在处理哪些槽</p>
<h3 id="集群中命令执行"><a href="#集群中命令执行" class="headerlink" title="集群中命令执行"></a>集群中命令执行</h3><h4 id="命令执行流程"><a href="#命令执行流程" class="headerlink" title="命令执行流程"></a>命令执行流程</h4><p>指派完所有的槽以后，集群会进入上线状态，此时客户端可以向集群中的节点发送数据命令</p>
<p>当客户端向节点发送与数据库键有关的命令时，<strong>接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己：</strong></p>
<ul>
<li>如果指派给自己，执行</li>
<li>否则，返回MOVED错误，并<strong>将客户端指向正确的节点</strong></li>
</ul>
<h4 id="MOVED错误"><a href="#MOVED错误" class="headerlink" title="MOVED错误"></a>MOVED错误</h4><p>当节点发现键所在的槽并非由自己负责处理的时候，节点就会向客户端返回一个MOVED错误，指引客户端转向至正在负责槽的节点</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// MOVED错误的格式</span></span><br><span class="line">MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;</span><br></pre></td></tr></table></figure>

<p><strong>MOVED简单实现原理</strong>：一个集群客户端通常会与集群中的多个节点创建套接字连接，而所谓的节点转向实际上就是换一个套接字发送命令（如果客户端尚未与想要转向的节点创建套接字连接，那么客户端会先根据MOVED错误提供的IP地址和端口号来连接节点，然后再进行转向）</p>
<h4 id="节点数据库实现"><a href="#节点数据库实现" class="headerlink" title="节点数据库实现"></a>节点数据库实现</h4><p>集群节点<strong>保存键值对</strong>以及<strong>键值对过期时间</strong>的方式，与单机Redis服务器完全相同</p>
<p>节点和单机服务器在数据库方面的一个区别是，节点只能使用0号数据库，而单机Redis服务器则没有这一限制</p>
<p>除了将键值对保存在数据库里面之外，节点还会有clusterState结构中的slots_to_keys跳跃表来保存槽和键之间的关系。slots_to_keys跳跃表每个节点的分值（score）都是一个槽号，而每个节点的成员（member）都是一个数据库键，通过在slots_to_keys跳跃表中记录各个数据库键所属的槽，节点可以很方便的对属于某个或某些槽的所有数据库键进行批量操作  </p>
<h3 id="重新分片"><a href="#重新分片" class="headerlink" title="重新分片"></a>重新分片</h3><h4 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h4><p>Redis集群的重新分片操作可以将<strong>任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点）</strong>，并且相关槽所属的键值对也会从源节点被移动到目标节点</p>
<p>重新分片操作可以<strong>在线（online）进行</strong>，在重新分片的过程中，集群不需要下线，并且<strong>源节点和目标节点都可以继续处理命令请求</strong></p>
<h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>Redis集群的重新分片操作是由Redis的集群管理软件<strong>redis-trib</strong>负责执行的，<strong>Redis提供了进行重新分片所需的所有命令</strong>，而redis-trib则<strong>通过向源节点和目标节点发送命令来进行重新分片操作</strong></p>
<p>重新分配步骤如下：</p>
<p><img src="https://uk-1259555870.cos.eu-frankfurt.myqcloud.com/20200112105535.png" alt="img"></p>
<p>如果重新分片涉及多个槽，那么redis-trib将对每个给定的槽分别执行上面给出的步骤。</p>
<p><img src="https://uk-1259555870.cos.eu-frankfurt.myqcloud.com/20200112105711.png" alt="img"></p>
<h4 id="重新分片中的转向"><a href="#重新分片中的转向" class="headerlink" title="重新分片中的转向"></a>重新分片中的转向</h4><h5 id="ASK错误"><a href="#ASK错误" class="headerlink" title="ASK错误"></a>ASK错误</h5><p><strong>正在重新分片时</strong>，属于被迁移槽的一部分键值对保存在源节点里面，而另一部分键值对则保存在目标节点里面</p>
<p>当客户端向源节点发送一个与数据库键有关的命令，并且命令要处理的数据库键恰好就属于正在被迁移的槽时：</p>
<ul>
<li>槽在自己这里，执行客户端命令</li>
<li>槽不在，返回ASK错误，指引客户端转向正在导入槽的目标节点</li>
</ul>
<p>ASK错误实现原理</p>
<ol>
<li><code>clusterState</code>结构的<code>importing_slots_from</code>数组记录了当前节点正在从其他节点导入的槽</li>
<li><code>clusterState</code>结构的<code>migrating_slots_to</code>数组记录了当前节点正在迁移至其他节点的槽</li>
<li>通过<code>migrating_slots_to</code>这个数组，我们知道当前节点的某个键是否正在迁移。如果是则返回ASK错误</li>
</ol>
<p><img src="https://xiaoyue26.github.io/images/2019-03/ask_query.png" alt="img"></p>
<p>ASKING命令的目的就是打开REDIS_ASKING标识，而且<strong>是一次性的打开</strong>，意味着使用完后会被关闭。</p>
<p>当客户端收到ASK错误并转向正在导入槽的节点时，客户端会先向节点发送一个ASKING命令，然后才重新发送想要执行的命令，这是因为如果客户端不发送ASKING命令，而直接发送想要执行的命令的话，那么客户端发送的命令会被节点拒绝执行，并返回MOVED错误</p>
<h3 id="转向"><a href="#转向" class="headerlink" title="转向"></a>转向</h3><p>ASK错误和MOVED错误都会导致客户端转向，它们的区别在于：</p>
<ul>
<li>MOVED错误代表槽的负责权已经从一个节点转移到了另一个节点：在客户端收到关于槽i的MOVED错误之后，客户端每次遇到关于槽i的命令请求时，都可以直接将命令请求发送至MOVED错误所指向的节点，因为该节点就是目前负责槽i的节点</li>
<li>与此相反，ASK错误只是两个节点在迁移槽的过程中使用的一种临时措施：在客户端收到关于槽i的ASK错误之后，客户端只会在接下来的一次命令请求中将关于槽i的命令请求发送至ASK错误所指示的节点，但这种转向不会对客户端今后发送关于槽i的命令产生任何影响，客户端仍然会将关于槽i的命令请求发送至目前负责处理槽i的节点，除非ASK错误再次出现</li>
</ul>
<h3 id="故障转移-1"><a href="#故障转移-1" class="headerlink" title="故障转移"></a>故障转移</h3><p>Redis集群中的节点分为主节点和从节点，其中主节点用于处理槽，而从节点则用于复制某个主节点，并在被复制的主节点下线时，代替下线主节点继续处理命令请求</p>
<p><strong>故障转移的整体思路与哨兵模式类似，主要是节点复制、检测节点是否下线以及对下线主节点进行故障</strong></p>
<ol>
<li><p>设置从节点 — 接收到命令的从节点开始对主节点进行复制</p>
</li>
<li><p>故障检测  </p>
<ol>
<li><strong>集群中的每个节点都会定期地向集群中的其它节点发送PING消息，以此来检测对方是否在线，如果接收PING消息的节点没有在规定的时间内，向发送PING消息的节点返回PONG消息，那么发送PING消息的节点就会将接收PING消息的节点标记为疑似下线</strong></li>
<li>如果在一个集群里面，半数以上负责处理槽的主节点都会将某个主节点x报告为疑似下线，那么这个主节点x将被标记为已下线，将主节点x标记为已下线的节点会向集群广播一条关于主节点x已下线的消息，所有收到这条消息的节点都立即将主节点x标记为已下线</li>
</ol>
</li>
<li><p>故障转移</p>
<p>选出新的主节点-&gt;槽指派-&gt;集群广播</p>
<p>当一个从节点发现自己正在复制的主节点进入了已下线状态时，从节点将开始对下线主节点进行故障转移，以下是故障转移的执行步骤：</p>
<ol>
<li>从已下线主节点中选出一个从节点</li>
<li>从节点执行SLAVEOF no one命令，成为新的主节点</li>
<li>新的主节点会撤销所有对已下线主节点的槽指派，并将这些槽全部指派给自己</li>
<li>新的主节点向集群广播一条PONG消息，这条PONG消息可以让集群中的其他节点立即知道这个节点已经由从节点变成了主节点。</li>
<li>新的主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成</li>
</ol>
</li>
</ol>
<h3 id="消息"><a href="#消息" class="headerlink" title="消息"></a>消息</h3><p><strong>集群中的各个节点通过发送和接收消息（message）来进行通信</strong>，节点发送的消息主要有以下五种：</p>
<ul>
<li><strong>MEET消息：</strong>当发送者接到客户端发送的CLUSTER MEET命令时，发送者会<strong>向接收者</strong>发送MEET消息，请求接收者加入到发送者当前所处的集群里面</li>
<li><strong>PING消息：</strong>集群里的每个节点默认每隔一秒钟就会从<strong>已知节点列表中随机选出五个节点</strong>，然后对这五个节点中最长时间没有发送过PING消息的节点发送PING消息，以此来检测被选中的节点是否在线</li>
<li><strong>PONG消息：</strong>当接收者收到发送者发来的MEET消息或者PING消息时，为了向发送者确认这条MEET消息或者PING消息已到达，接收者<strong>会向发送者</strong>返回一条PONG消息。另外，一个节点也可以通过向<strong>集群广播</strong>自己的PONG消息来让集群中的其他节点立即刷新关于这个节点的认识</li>
<li><strong>FAIL消息：</strong>当一个主节点A判断另一个主节点B已经进入FAIL状态时，节点A会<strong>向集群广播</strong>一条关于节点B的FAIL消息，所有收到这条消息的节点都会立即将节点B标记为已下线</li>
<li><strong>PUBLISH消息</strong>：当节点接收到一个PUBLISH命令时，节点会执行这个命令，并<strong>向集群广播</strong>一条PUBLISH消息，所有接收到这条PUBLISH消息的节点都会执行相同的PUBLISH命令</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] 黄健宏. Redis设计与实现[M]. 机械工业出版社, 2014.</p>
<p>[2] <a href="https://juejin.im/post/5d776dcef265da03b574744d" target="_blank" rel="noopener">https://juejin.im/post/5d776dcef265da03b574744d</a></p>
<p>[3] <a href="https://juejin.im/post/5b7d226a6fb9a01a1e01ff64" target="_blank" rel="noopener">https://juejin.im/post/5b7d226a6fb9a01a1e01ff64</a></p>
<p>[4] <a href="https://zhuanlan.zhihu.com/p/86995658" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/86995658</a></p>
<p>[5] <a href="https://blog.csdn.net/zlfprogram/java/article/details/77715714" target="_blank" rel="noopener">https://blog.csdn.net/zlfprogram/java/article/details/77715714</a></p>
<p>[6] Redis博客 <a href="https://jiangren.work/tags/Redis/" target="_blank" rel="noopener">https://jiangren.work/tags/Redis/</a></p>
]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>LockFreeQueue</title>
    <url>/2020/04/01/LockFreeQueue/</url>
    <content><![CDATA[<h1 id="LockFreeQueue"><a href="#LockFreeQueue" class="headerlink" title="LockFreeQueue"></a>LockFreeQueue</h1><blockquote>
<p>没什么好说的，直接附上源码和注释</p>
</blockquote>
<p>LockFreeQueue的起源：主要在自己造服务器轮子的时候，为了较少异步任务调配的开销，改用了无锁编程，下面的代码极力的控制了CAS自旋的粒度，避免某一个线程占用节点的时候，其余线程出现忙等待的状态。</p>
<p><strong>代码实现主要这篇论文</strong> -&gt; <a href="https://www.cs.rochester.edu/u/scott/papers/1996_PODC_queues.pdf" target="_blank" rel="noopener">[参考论文]</a></p>
<a id="more"></a>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;atomic&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt; <span class="class"><span class="keyword">class</span> <span class="title">LockFreeQueue</span> &#123;</span></span><br><span class="line">  <span class="comment">// 用链表实现LockFreeQueue --- Node定义节点的类型</span></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">    T data_;</span><br><span class="line">    Node *next_;</span><br><span class="line">    Node() : data_(), next_(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    Node(T &amp;data) : data_(data), next_(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">    Node(<span class="keyword">const</span> T &amp;data) : data_(data), next_(<span class="literal">nullptr</span>) &#123;&#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  Node *head_, *tail_;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  LockFreeQueue() : head_(<span class="keyword">new</span> Node()), tail_(head_) &#123;&#125;</span><br><span class="line">  ~LockFreeQueue() &#123;</span><br><span class="line">    Node *tmp;</span><br><span class="line">    <span class="keyword">while</span> (head_ != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">      tmp = head_;</span><br><span class="line">      head_ = head_-&gt;next_;</span><br><span class="line">      <span class="keyword">delete</span> tmp;</span><br><span class="line">    &#125;</span><br><span class="line">    tmp = <span class="literal">nullptr</span>;</span><br><span class="line">    tail_ = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">bool</span> <span class="title">Try_Dequeue</span><span class="params">(T &amp;data)</span> </span>&#123;</span><br><span class="line">    Node *old_head, *old_tail, *first_node;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">      <span class="comment">// 取出头指针，尾指针，和第一个元素的指针</span></span><br><span class="line">      old_head = head_;</span><br><span class="line">      old_tail = tail_; <span class="comment">// 前面两步的顺序非常重要，一定要在获取old_tail之前获取old_head</span></span><br><span class="line">                        <span class="comment">// 保证old_head_不落后于old_tail</span></span><br><span class="line">      first_node = old_head-&gt;next_;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 下面的工作全是在确保上面三个指针的“一致性”</span></span><br><span class="line">      <span class="comment">// 1. 保证head_的一致性</span></span><br><span class="line">      <span class="comment">// head_ 指针已移动，重新取 head指针</span></span><br><span class="line">      <span class="keyword">if</span> (old_head != head_) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 2. 保证尾指针落后于头指针 (尾指针与全局尾指针部分一致性保持)</span></span><br><span class="line">      <span class="comment">// 空队列 或者 全局尾指针落后了？</span></span><br><span class="line">      <span class="comment">// 落后是指其他线程的已经更新，而当前线程没有更新</span></span><br><span class="line">      <span class="keyword">if</span> (old_head == old_tail) &#123;</span><br><span class="line">        <span class="keyword">if</span> (first_node == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 证明全局尾指针没有被更新，尝试更新一下 “主动操作”</span></span><br><span class="line">        ::__sync_bool_compare_and_swap(&amp;tail_, old_tail, first_node);</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="comment">// 前面的操作都是在确保全局尾指针在全局头指针之后，只有这样才能安全的删除数据</span></span><br><span class="line">      &#123;</span><br><span class="line">        <span class="comment">// 在CAS前先取出数据，防止其他线程dequeue造成数据的缺失</span></span><br><span class="line">        data = first_node-&gt;data_;</span><br><span class="line">        <span class="comment">// 移动 old_head 指针成功则退出</span></span><br><span class="line">        <span class="keyword">if</span> (::__sync_bool_compare_and_swap(&amp;head_, old_head, first_node)) &#123;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">delete</span> old_head;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">Enqueue</span><span class="params">(<span class="keyword">const</span> T &amp;data)</span> </span>&#123;</span><br><span class="line">    Node *enqueue_node = <span class="keyword">new</span> Node(data);</span><br><span class="line">    Node *old_tail, *old_tail_next;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">      <span class="comment">//先取一下尾指针和尾指针的next</span></span><br><span class="line">      old_tail = tail_;</span><br><span class="line">      old_tail_next = old_tail-&gt;next_;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//如果尾指针已经被移动了，则重新开始</span></span><br><span class="line">      <span class="keyword">if</span> (old_tail != tail_) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 判断尾指针是否指向最后一个节点</span></span><br><span class="line">      <span class="keyword">if</span> (old_tail_next == <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (::__sync_bool_compare_and_swap(&amp;(old_tail-&gt;next_), old_tail_next,</span><br><span class="line">                                           enqueue_node)) &#123;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 全局尾指针不是指向最后一个节点，就把全局尾指针向后移动</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 全局尾指针不是指向最后一个节点，发生在其他线程已经完成节点添加操作，</span></span><br><span class="line">        <span class="comment">// 但是并没有更新最后一个节点，此时，当前线程的(tail_和old_tail是相等的，)</span></span><br><span class="line">        <span class="comment">// 可以更新全局尾指针为old_tail_next，如果其他线程不更新全局尾指针，</span></span><br><span class="line">        <span class="comment">// 那么当前线程会不断移动，直到  old_tail_next == nullptr 为true</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 为什么这里不直接Continue 原因是:</span></span><br><span class="line">        <span class="comment">// 如果其他线程添加了节点，但是并没有更新</span></span><br><span class="line">        <span class="comment">// 全局尾节点，就会导致所有的线程原地循环等待，所以每一个线程必须要有一些</span></span><br><span class="line">        <span class="comment">// “主动的操作” 去获取尾节点，这种思想在 dequeue的时候也有体现</span></span><br><span class="line">        ::__sync_bool_compare_and_swap(&amp;(tail_), old_tail, old_tail_next);</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 重置尾节点, (也有可能已经被别的线程重置，那么当前线程就不用管了</span></span><br><span class="line">    ::__sync_bool_compare_and_swap(&amp;tail_, old_tail, enqueue_node);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>并发</category>
      </categories>
      <tags>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title>string的短字符优化</title>
    <url>/2020/03/23/StringSSO/</url>
    <content><![CDATA[<h1 id="string的短字符优化"><a href="#string的短字符优化" class="headerlink" title="string的短字符优化"></a>string的短字符优化</h1><p>之所以有这篇文章是因为在完成项目的时候遇到了一个问题，百思不得其解！最后借助了在强大的StackOverflow上提问，才解决这个问题。因为项目比较复杂，所以只能把关键部分提取出来，重现一下问题的场景。</p>
<a id="more"></a>

<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><p>Note: 下面的代码模拟的真实coding的一部分</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 这串代码，逻辑上是错误的，临时对象data被销毁，但是子线程却还在持有引用</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// !!! 但是代码运行的结果却是正确的</span></span><br><span class="line"><span class="comment">// 更加有趣的事情是 当把 data 的长度设置为 17个字符的时候，乱码了，出错了</span></span><br><span class="line"><span class="comment">// hah，等下揭秘</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;thread&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">thfunc</span><span class="params">(<span class="built_in">string</span> &amp;data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; data &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">string</span> data = <span class="string">"123"</span>;</span><br><span class="line">        <span class="function"><span class="built_in">std</span>::thread <span class="title">th1</span><span class="params">(thfunc, <span class="built_in">std</span>::ref(data))</span></span>;</span><br><span class="line">        th1.detach();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (;;)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">cout</span> &lt;&lt; <span class="string">"main loop"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="问题的分析及解决"><a href="#问题的分析及解决" class="headerlink" title="问题的分析及解决"></a>问题的分析及解决</h2><p><a href="https://stackoverflow.com/questions/61399544/thread-safety-with-c11-and-passing-by-reference-with-temporary-object" target="_blank" rel="noopener">[自己在stackoverflow上提的问题, 有人给出了精致的回答]</a></p>
<p>The temporary object is released per the standard, leading to <em>undefined behavior</em>. An implementation may do anything, including keeping the object’s bytes in stack memory until they are overwritten, which allows your code to (incorrectly) work.</p>
<p>When I disassembled the binary produced by my compiler (clang++ 9.0.1) I noticed that the stack pointer was not “regressed” when the block containing <code>data</code> ended, thus preventing it from being overwritten when <code>cout &lt;&lt; &quot;main loop&quot; &lt;&lt; endl;</code> resulted in function calls.</p>
<p>Furthermore, due to <a href="https://shaharmike.com/cpp/std-string/" target="_blank" rel="noopener">short string optimization</a>, the actual ASCII “123” is stored within the <code>std::string</code> object itself and not in a heap-allocated buffer.</p>
<p>Experimentally, if I make the string long enough to disable short string optimization, the program still silently works since the bytes in the buffer happen to remain intact <em>in my experiment</em>. If I enable ASAN, I get a correct heap use-after-free warning, because the bytes were freed at the end of the string’s lifetime, yet were accessed through an illegal use of a pointer to the now-destructed string.</p>
<h3 id="短字符优化"><a href="#短字符优化" class="headerlink" title="短字符优化"></a>短字符优化</h3><p>上面的大意就是：字符串长度小于1５时，使用的是短字符优化，此时存在string本身的local buffer上，[此时产生的未定义行为可能是编译器保持了这个栈上的内存，直到他们被重写，所以有可能出现被“销毁”后还能打印出来的情况]</p>
<p>如果增大字符串的长度就有极大可能显现错误</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 其内部成员的实现如下图所示</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">size_t</span> m_size; <span class="comment">// string 的长度</span></span><br><span class="line"><span class="keyword">size_t</span> m_capacity;</span><br><span class="line"><span class="keyword">union</span> <span class="comment">//  储存string</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">char</span> buffer[local_buf_size];　<span class="comment">// local_buf_size = 15</span></span><br><span class="line">    <span class="keyword">char</span> *ptr;</span><br><span class="line">&#125; m_data;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>STL</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title>调试神器Valgrind</title>
    <url>/2020/02/25/Debug%E7%A5%9E%E5%99%A8Valgrind/</url>
    <content><![CDATA[<h1 id="Valgrind"><a href="#Valgrind" class="headerlink" title="Valgrind"></a>Valgrind</h1><p>在完成项目的过程中少不了要检查内存错误，发现潜在的线程安全问题，这时候就要借助强大的分析工具了。Valgrind也是自己在写大型项目的时候发现，竟有此等神器，便觉得这么好的东西一定要分享记录！本文主要参照徐晓鑫《后台开发：核心技术与应用实践》一书撰写，其实也是<strong>实践</strong>笔记。</p>
<a id="more"></a>

<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Valgrind由内核（core）以及基于内核的其他调试工具组成。内核类似于一个框架（framework），它模拟了一个CPU环境，并提供服务给其他工具；而其他工具则类似于插件 (plug-in)，利用内核提供的服务完成各种特定的内存调试任务</p>
<h2 id="valgrind工具"><a href="#valgrind工具" class="headerlink" title="valgrind工具"></a>valgrind工具</h2><p>（1）Memcheck: 这是valgrind应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如: 使用未初始化的内存，使用已经释放了的内存，内存访问越界等。这也是本文将重点介绍的部分。</p>
<p>（2）Callgrind: 它主要用来检查程序中函数调用过程中出现的问题</p>
<p>（3）Cachegrind: 它主要用来检查程序中缓存使用出现的问题，Cache分析器，它模拟CPU中的一级缓存和二级缓存，能够精确地支出程序中的Cache的丢失和命中，如果需要，他还能够为用户提供Cache丢失此时、内存引用次数以及每行代码、每个函数、每个模块及整个程序产生的指令数</p>
<p>（4）Helgrind: 它主要用来检查多线程程序中出现的竞争问题，Helgrind寻找内存中被多个线程访问，而又没有一贯加锁的区域，这些区域往往是线程之间失去同步的地方，而且会导致难以发觉的错误。Helgrind实现了名为Eraser的竞争检测算法，并做了进一步改进，减少了错误报告的次数</p>
<p>（5）Massif: 堆栈分析器，它主要用来检查程序中堆栈使用中出现的问题</p>
<p>（6）Extension: 可以利用core提供的功能，自己编写特定的内存调试工具</p>
<h2 id="内存检查原理"><a href="#内存检查原理" class="headerlink" title="内存检查原理"></a>内存检查原理</h2><img src="https://pic4.zhimg.com/80/v2-a83000aabd735df71612bd79e696f62b_1440w.jpg" alt="img" style="zoom:150%;" />

<p><strong>Memcheck 能够检测出内存问题，关键在于其建立了两个全局表</strong></p>
<p>1.Valid-Value 表：</p>
<p>对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个 bits；对于 CPU 的每个寄存器，也有一个与之对应的 bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。</p>
<p>2.Valid-Address 表</p>
<p>对于进程整个地址空间中的每一个字节(byte)，还有与之对应的 1 个 bit，负责记录该地址是否能够被读写。</p>
<p>检测原理: 当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，memcheck 则报告读写错误。</p>
<p>内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] 徐晓鑫 后台开发：核心技术与应用实践</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>迭代器失效</title>
    <url>/2020/02/23/%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="真正的迭代器失效"><a href="#真正的迭代器失效" class="headerlink" title="真正的迭代器失效"></a>真正的迭代器失效</h1><p>erase之后某个迭代器之后，后面的迭代器真的失效了吗？失效了到底是什么意思？这个问题有趣的很哈哈哈！</p>
<a id="more"></a>

<h2 id="问题现象来源"><a href="#问题现象来源" class="headerlink" title="问题现象来源"></a>问题现象来源</h2><p>在Windows VS下，下面的代码在Release模式下,是不会出错的，在Debug模式下会出错</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;deque&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; data = &#123; <span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>,<span class="number">10</span> &#125;;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">auto</span> it0 = data.begin();</span><br><span class="line">	<span class="keyword">auto</span> it1 = it0 + <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">auto</span> it2 = it0 + <span class="number">2</span>;</span><br><span class="line">	<span class="keyword">auto</span> it = data.erase(it1);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 下面的代码在Release模式下,是不会出错的，在Debug模式下会出错</span></span><br><span class="line">	<span class="built_in">cout</span> &lt;&lt; (*it2) &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h2 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h2><h3 id="先给结论"><a href="#先给结论" class="headerlink" title="先给结论"></a>先给结论</h3><p>通过下面的代码可以看出以及对源码的分析，迭代器失效只是因为他们里面的属性设设置了，使得Debug模式下，在合法性检查的时候，会出错，而在Release下却没有问题，个人觉得迭代器失效的英文迭代器 invalidation可以更好的解释，迭代器是不合法的，即使你能是程序得到正确的运行，但是访问结果可能出了问题</p>
<blockquote>
<p> erase引起的迭代器失效，只是因为，erase一个迭代器之后，程序会把后面的迭代器全部标记为孤儿，而在Debug模式下，程序会检查迭代器是否是孤儿，是的话则会爆出迭代器失效的错误！</p>
</blockquote>
<h3 id="源码剖析"><a href="#源码剖析" class="headerlink" title="源码剖析"></a>源码剖析</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">reference <span class="keyword">operator</span>*() <span class="keyword">const</span></span><br><span class="line">	&#123;	<span class="comment">// return designated object</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> _ITERATOR_DEBUG_LEVEL == 2</span></span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">auto</span> _Mycont = <span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> _Myvec *&gt;(<span class="keyword">this</span>-&gt;_Getcont()); <span class="comment">// 获得容器</span></span><br><span class="line">	<span class="keyword">if</span> (_Mycont == <span class="number">0</span></span><br><span class="line">		|| _Ptr == _Tptr()</span><br><span class="line">		|| _Ptr &lt; _Mycont-&gt;_Myfirst</span><br><span class="line">		|| _Mycont-&gt;_Mylast &lt;= _Ptr)</span><br><span class="line">		&#123;	<span class="comment">// report error</span></span><br><span class="line">		_DEBUG_ERROR(<span class="string">"vector iterator not dereferencable"</span>);</span><br><span class="line">		_SCL_SECURE_OUT_OF_RANGE;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> _ITERATOR_DEBUG_LEVEL == 1</span></span><br><span class="line">	_SCL_SECURE_VALIDATE(_Ptr != _Tptr());</span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">auto</span> _Mycont = <span class="keyword">static_cast</span>&lt;<span class="keyword">const</span> _Myvec *&gt;(<span class="keyword">this</span>-&gt;_Getcont());</span><br><span class="line">	_SCL_SECURE_VALIDATE(_Mycont != <span class="number">0</span>);</span><br><span class="line">	_SCL_SECURE_VALIDATE_RANGE(_Mycont-&gt;_Myfirst &lt;= _Ptr &amp;&amp; _Ptr &lt; _Mycont-&gt;_Mylast);</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* _ITERATOR_DEBUG_LEVEL */</span></span></span><br><span class="line"></span><br><span class="line">	_Analysis_assume_(_Ptr != _Tptr());</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> (*_Ptr);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> _Container_base12 *_Getcont() <span class="keyword">const</span></span><br><span class="line">	&#123;	<span class="comment">// get owning container</span></span><br><span class="line">   <span class="comment">// _Myproxy == 0 为true,表示是一个失效的迭代器</span></span><br><span class="line">	<span class="keyword">return</span> (_Myproxy == <span class="number">0</span> ? <span class="number">0</span> : _Myproxy-&gt;_Mycont);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 在迭代器移动的时候会 实现invalid操作，孤立现在的迭代器</span></span><br><span class="line">_Iterator_base12&amp; <span class="keyword">operator</span>=(<span class="keyword">const</span> _Iterator_base12&amp; _Right)</span><br><span class="line">		&#123;	<span class="comment">// assign an iterator</span></span><br><span class="line">		<span class="keyword">if</span> (_Myproxy == _Right._Myproxy)</span><br><span class="line">			;</span><br><span class="line">		<span class="keyword">else</span> <span class="keyword">if</span> (_Right._Myproxy != <span class="number">0</span>)</span><br><span class="line">			_Adopt(_Right._Myproxy-&gt;_Mycont);</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">			&#123;	<span class="comment">// becoming invalid, disown current parent</span></span><br><span class="line"> #<span class="keyword">if</span> _ITERATOR_DEBUG_LEVEL == <span class="number">2</span></span><br><span class="line">			_Lockit _Lock(_LOCK_DEBUG);</span><br><span class="line">			_Orphan_me();</span><br><span class="line"> <span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* _ITERATOR_DEBUG_LEVEL == 2 */</span></span></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">return</span> (*<span class="keyword">this</span>);</span><br><span class="line">		&#125;</span><br></pre></td></tr></table></figure>



<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> _Adopt(<span class="keyword">const</span> _Container_base12 *_Parent)</span><br><span class="line">	&#123;	<span class="comment">// adopt this iterator by parent</span></span><br><span class="line">	<span class="keyword">if</span> (_Parent == <span class="number">0</span>)</span><br><span class="line">		&#123;	<span class="comment">// no future parent, just disown current parent</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> _ITERATOR_DEBUG_LEVEL == 2</span></span><br><span class="line">		_Lockit _Lock(_LOCK_DEBUG);</span><br><span class="line">		_Orphan_me();</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* _ITERATOR_DEBUG_LEVEL == 2 */</span></span></span><br><span class="line">		&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		&#123;	<span class="comment">// have a parent, do adoption</span></span><br><span class="line">		_Container_proxy *_Parent_proxy = _Parent-&gt;_Myproxy;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> _ITERATOR_DEBUG_LEVEL == 2</span></span><br><span class="line">		<span class="keyword">if</span> (_Myproxy != _Parent_proxy)</span><br><span class="line">			&#123;	<span class="comment">// change parentage</span></span><br><span class="line">			_Lockit _Lock(_LOCK_DEBUG);</span><br><span class="line">			_Orphan_me();</span><br><span class="line">			_Mynextiter = _Parent_proxy-&gt;_Myfirstiter;</span><br><span class="line">			_Parent_proxy-&gt;_Myfirstiter = <span class="keyword">this</span>;</span><br><span class="line">			_Myproxy = _Parent_proxy;</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span> <span class="comment">/* _ITERATOR_DEBUG_LEVEL == 2 */</span></span></span><br><span class="line">		_Myproxy = _Parent_proxy;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* _ITERATOR_DEBUG_LEVEL == 2 */</span></span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>



]]></content>
      <categories>
        <category>STL</category>
      </categories>
      <tags>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title>锁优化</title>
    <url>/2020/06/23/%E9%94%81%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="锁优化"><a href="#锁优化" class="headerlink" title="锁优化"></a>锁优化</h1><p>最近在公司实习，见证了因为锁的选择不当导致了服务器宕机，这里由于保密规定，不能泄露太多，只能从书本知识上尽量模拟一下场景，好记住教训。<strong>本文即将涉及特定场景下锁选择问题，以及优化锁的临界区长度还有如何减小锁的粒度</strong></p>
<a id="more"></a>

<h2 id="最简单的加锁方式"><a href="#最简单的加锁方式" class="headerlink" title="最简单的加锁方式"></a>最简单的加锁方式</h2><p>如果不考虑任何场景，最简单的加锁方式如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">mutex g_mutex;</span><br><span class="line">g_mutex.lock();</span><br><span class="line"><span class="comment">// do something</span></span><br><span class="line">g_mutex.unlock();</span><br></pre></td></tr></table></figure>

<p>上面的代码没有针对特定场景进行优化，而且当临界区代码执行时间较长时，一个线程执行任务，其余线程都得等待，这个时候上面的代码在高并发环境下就显得很错误了。</p>
<blockquote>
<p>注意: 在于自旋锁对比的时候，如果临界区代码执行时间较长，建议选择互斥锁。</p>
</blockquote>
<h4 id="如何优化"><a href="#如何优化" class="headerlink" title="如何优化"></a>如何优化</h4><p>考虑特定场景，我遇到的是一个<strong>读远大于写</strong>的业务，那么此时可以将读写线程分开加锁，也就是使用<strong>读写锁</strong>，读写锁的大致伪代码如下，之后我会专门写一个关于读写锁的博客(重点讲述下如何避免饥饿，也就是读优先、写优先或者是读写平等)</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 读写锁大致伪代码如下</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RWLock</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lockR</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlockR</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">lockW</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">unlockW</span><span class="params">()</span></span>&#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>根据上面的读写锁，那么在读线程中可以根据下面的代码段加锁</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">RWLock rw_lock;</span><br><span class="line">rw_lock.lockR();</span><br><span class="line"><span class="comment">// read data</span></span><br><span class="line">rw_lock.unlockR();</span><br></pre></td></tr></table></figure>

<p>同理，那么在写线程中可以根据下面的代码段加锁</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">RWLock rw_lock;</span><br><span class="line">rw_lock.lockW();</span><br><span class="line"><span class="comment">// write data</span></span><br><span class="line">rw_lock.unlockW();</span><br></pre></td></tr></table></figure>

<h4 id="重点来了"><a href="#重点来了" class="headerlink" title="重点来了"></a>重点来了</h4><p>虽然实现了读写线程分离，但是这真的就完美了吗？</p>
<p>先给结论，永远存在更优秀的办法，等着你去挖掘！！！</p>
<blockquote>
<p>当写线程的一直占用临界区的时候，那么大量的读线程岂不是都要干瞪眼等着？</p>
</blockquote>
<p>如何优化呢？其实这里可以让写线程先把要写的数据准备好，等真正加锁的时候，只是交换一下指针，那么这样可以大大减少临界区的长度。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Data* data; <span class="comment">// data是 读写线程都能接触到的数据</span></span><br><span class="line"></span><br><span class="line">Data* data_copy = data; <span class="comment">// 存在写线程的数据备份</span></span><br><span class="line">WriteSomething(data_copy); <span class="comment">// 现将数据写入data_copy</span></span><br><span class="line">RWLock rw_lock;</span><br><span class="line">rw_lock.lockW();</span><br><span class="line">swap(data, data_copy); <span class="comment">// 这里不管你的写入数据有代码多长，执行时间有多久，最后都优化成了两步</span></span><br><span class="line">data_copy = data;      <span class="comment">// 而且这里只是指针的交换，可以说是极大的减小了临界区</span></span><br><span class="line">rw_lock.unlockW();</span><br></pre></td></tr></table></figure>

<h4 id="更优的办法"><a href="#更优的办法" class="headerlink" title="更优的办法"></a>更优的办法</h4><p>当然了，优秀的代码永远层出不穷！</p>
<p>利用读写锁只是将读写线程分开，若要将锁的粒度减小到最低，就必须将所有的线程全部分开，减小锁冲撞的概率，优化锁的粒度，这里介绍下Baidu的DoublyBufferedData</p>
<p><strong>其基本实现如下</strong>：每一份读线程拿一把自己的 thread-local 锁，写需要拿到所有的 thread-local 锁之后才能开始交换Buffer, 这里写线程有两块Buffer, 用来优化临界区，优化方式在上面已经介绍。</p>
<p>直观上，这种加锁方式和直接使用读写锁差别不大：读请求不相互阻塞，读写请求会相互阻塞。相比读写锁，这种加锁方式的好处是，writer 每次只会阻塞一个 reader 线程，这样即使writer拿锁时间较长，也不会阻碍所有的读线程</p>
<h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>锁的选择要根据特定场景，然后还要对临界区以及锁的粒度进行合理的优化，才能不出事啊！</p>
]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title>快速排序(迭代版)</title>
    <url>/2020/03/22/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F-%E8%BF%AD%E4%BB%A3%E6%B3%95/</url>
    <content><![CDATA[<h1 id="QuickSort"><a href="#QuickSort" class="headerlink" title="QuickSort"></a>QuickSort</h1><blockquote>
<p>起源于面试的时候，面试官叫我手撕一下快速排序算法，于是我按照常规思路（递归）写出来后，面试官才开始真正抛出问题，请你修改成迭代的快排？当时稍稍卡了一下，后来马上反应过来，一定是用栈来模拟函数调用，于是稍稍修改代码就写出来了，作为一个乐于分享的人，当然要记录一下啦</p>
</blockquote>
<a id="more"></a>

<h2 id="递归法"><a href="#递归法" class="headerlink" title="递归法"></a>递归法</h2><p>这个是最容易想到的，先寻找枢纽，然后减小了问题规模，最后再分段重新调用快速排序函数即可！</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="built_in">vector</span>&lt;<span class="keyword">int</span>&gt; vi;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">partition</span><span class="params">(vi&amp; data, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> pivot = data[right];			<span class="comment">// 枢纽值</span></span><br><span class="line">	<span class="keyword">int</span> i = left;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> j = i; j &lt; right; ++j) &#123;</span><br><span class="line">		<span class="keyword">if</span> (data[j] &lt; pivot)</span><br><span class="line">		&#123;</span><br><span class="line">			swap(data[j], data[i++]);   <span class="comment">// 小于的提前，大于的放后</span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	swap(data[right], data[i]);         <span class="comment">// 中轴值提前，划分两边</span></span><br><span class="line">	<span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quicksort</span><span class="params">(vi&amp; data, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (left &gt;= right) &#123;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">int</span> pivot_index = partition(data, left, right);</span><br><span class="line">	quicksort(data, left, pivot_index - <span class="number">1</span>);</span><br><span class="line">	quicksort(data, pivot_index + <span class="number">1</span>, right);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>下面才是我们的重点！！！</p>
</blockquote>
<h2 id="迭代法"><a href="#迭代法" class="headerlink" title="迭代法"></a>迭代法</h2><p>迭代法实现快排其实不难，主要在于想到如何将多次函数调用给去掉，在数据结构里面，容易与函数调用放在一起的就是栈了，我们都知道函数调用实际上就是利用栈先入后出的特点</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// partition 函数与之前相同</span></span><br><span class="line"><span class="keyword">typedef</span> pair&lt;<span class="keyword">int</span>, <span class="keyword">int</span>&gt; pii;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">quicksort</span><span class="params">(vi&amp; data, <span class="keyword">int</span> left, <span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">if</span> (left &gt;= right) &#123;</span><br><span class="line">		<span class="keyword">return</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">stack</span>&lt;pii&gt; stk;</span><br><span class="line">	stk.push(&#123; left, right &#125;);</span><br><span class="line">	<span class="keyword">while</span> (!stk.empty())</span><br><span class="line">	&#123;</span><br><span class="line">		pii cur = stk.top();</span><br><span class="line">		stk.pop();</span><br><span class="line">		<span class="keyword">int</span> pivot_index = partition(data, cur.first, cur.second);</span><br><span class="line">		<span class="keyword">if</span> (cur.first &lt; (pivot_index - <span class="number">1</span>)) &#123;</span><br><span class="line">			stk.push(&#123; cur.first, pivot_index - <span class="number">1</span> &#125;);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span> ((pivot_index + <span class="number">1</span>) &lt; cur.second)</span><br><span class="line">		&#123;</span><br><span class="line">			stk.push(&#123; pivot_index + <span class="number">1</span>, cur.second &#125;);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
</search>
